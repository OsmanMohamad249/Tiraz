name: CI Smoke E2E - Measurements

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  smoke-e2e-measurements:
    name: Smoke E2E - /api/v1/measurements/process
    runs-on: ubuntu-latest
    timeout-minutes: 20
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install dependencies (jq)
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq curl

      - name: Start Docker Compose services
        run: |
          set -euo pipefail
          # Generate a strong SECRET_KEY if not provided via repository secret
          SECRET_KEY="${{ secrets.CI_SECRET_KEY }}"
          if [ -z "$SECRET_KEY" ]; then
            SECRET_KEY=$(openssl rand -hex 32)
          fi
          # Do NOT print SECRET_KEY to logs. Persist to .ci.env for docker compose interpolation.
          echo "SECRET_KEY=$SECRET_KEY" > .ci.env

          # Ensure host-side ci-logs directory exists and will be mounted into containers
          mkdir -p ci-logs

          # Create docker-compose.ci.yml (same layout as backend CI) so compose can be
          # validated and started in this job's workspace.
          cat > docker-compose.ci.yml <<'YAML'
          version: "3.8"
          services:
            postgres:
              image: postgres:15
              environment:
                POSTGRES_USER: test_user
                POSTGRES_PASSWORD: test_password
                POSTGRES_DB: test_db
              ports:
                - "5432:5432"
              healthcheck:
                test: ["CMD-SHELL", "pg_isready -U test_user"]
                interval: 2s
                timeout: 2s
                retries: 30
            redis:
              image: redis:7
              ports:
                - "6379:6379"
              healthcheck:
                test: ["CMD", "redis-cli", "ping"]
                interval: 2s
                timeout: 2s
                retries: 30
            backend:
              build:
                context: .
                dockerfile: backend/Dockerfile
              environment:
                DATABASE_URL: postgresql://test_user:test_password@postgres:5432/test_db
                REDIS_URL: redis://redis:6379/0
                SECRET_KEY: "${SECRET_KEY}"
                AI_SERVICE_URL: http://ai-models:8000
                PYTHONPATH: "/app/backend"
              depends_on:
                - postgres
                - redis
                - ai-models
              ports:
                - "8000:8000"
              volumes:
                - ./:/app
                - ./ci-logs:/ci-logs
              working_dir: /app
              command: /bin/bash -lc "uvicorn backend.main:app --host 0.0.0.0 --port 8000"
            tester:
              build:
                context: .
                dockerfile: backend/Dockerfile
              environment:
                - DATABASE_URL=postgresql://test_user:test_password@postgres:5432/test_db
                - REDIS_URL=redis://redis:6379/0
                - SECRET_KEY=${SECRET_KEY}
                - PYTHONPATH=/app:/app/backend
              depends_on:
                - backend
                - ai-models
              volumes:
                - ./:/app
                - ./ci-logs:/ci-logs
              working_dir: /app
              command: /bin/bash -lc "sleep infinity"
            ai-models:
              build:
                context: ./ai-models
                dockerfile: Dockerfile
              ports:
                - "8001:8000"
              volumes:
                - ./ai-models:/app
          YAML

          # Validate docker compose interpolation before bringing services up
          docker compose -f docker-compose.ci.yml --env-file .ci.env config

          # Start only Postgres and Redis first so we can initialize DB before starting backend
          docker compose --env-file .ci.env -f docker-compose.ci.yml up -d postgres redis

      - name: Wait for Postgres readiness
        run: |
          set -euo pipefail
          echo "Waiting for Postgres to report ready..."
          for i in {1..60}; do
            docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T postgres pg_isready -U test_user && { echo "postgres ready"; exit 0; } || true
            sleep 1
          done
          echo "Postgres did not become ready"; exit 1

      - name: Initialize alembic_version table
        run: |
          set -euo pipefail
          echo "Creating/altering alembic_version table to ensure version_num VARCHAR(255) (run as postgres superuser)"
          mkdir -p ci-logs || true
          # Create a small idempotent SQL script and feed it to psql inside the postgres container.
          cat > /tmp/alembic_init.sql <<'SQL'
          CREATE TABLE IF NOT EXISTS alembic_version (version_num VARCHAR(255) NOT NULL PRIMARY KEY);
          DO $$
          BEGIN
            IF EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='alembic_version' AND column_name='version_num') THEN
              ALTER TABLE alembic_version ALTER COLUMN version_num TYPE VARCHAR(255);
            END IF;
          END
          $$;
          SQL

          # Feed the SQL into psql running in the postgres container and capture the output to host-side ci-logs
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T postgres psql -U test_user -d test_db -v ON_ERROR_STOP=1 -f - < /tmp/alembic_init.sql > ci-logs/alembic-init.log 2>&1 || true

          # Dump verification info so CI artifacts show the column type and any rows present
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T postgres psql -U test_user -d test_db -c "SELECT column_name, data_type, character_maximum_length FROM information_schema.columns WHERE table_name='alembic_version' AND column_name='version_num';" > ci-logs/alembic-pre-init-schema.log 2>&1 || true
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T postgres psql -U test_user -d test_db -c "SELECT * FROM alembic_version;" > ci-logs/alembic-pre-init-rows.log 2>&1 || true

      - name: Start backend and tester
        run: |
          set -euo pipefail
          echo "Starting backend and tester services"
          docker compose --env-file .ci.env -f docker-compose.ci.yml up --build -d backend tester

      - name: Inspect backend DB connection (redacted)
        run: |
          set -euo pipefail
          mkdir -p ci-logs || true
          echo "Writing redacted DATABASE_URL and connection info from backend to ci-logs"
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T backend bash -lc 'env | grep DATABASE_URL | sed -E "s#(//[^:]+):[^@]+@#\\1:*****@#"' > ci-logs/backend-db-url.log 2>&1 || true

      - name: Run Alembic migrations
        run: |
          set -euo pipefail
          # Ensure a host-side ci-logs dir exists (mounted into containers)
          mkdir -p ci-logs
          # Run alembic inside the backend container and have it write its log to the mounted /ci-logs
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T backend bash -lc "cd /app/backend && alembic -c alembic.ini upgrade head > /ci-logs/alembic.log 2>&1"
          # Also print the alembic log to the runner so the job output contains the migration trace
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T backend bash -lc "cat /ci-logs/alembic.log" || true

      - name: Dump users table after migrations (for debugging)
        run: |
          set -euo pipefail
          mkdir -p ci-logs || true
          echo "Dumping users table to ci-logs/users-after-migrations.log"
          docker compose --env-file .ci.env -f docker-compose.ci.yml exec -T postgres psql -U test_user -d test_db -c "SELECT email, hashed_password, is_active, is_superuser, role FROM users;" > ci-logs/users-after-migrations.log 2>&1 || true

      - name: Wait for backend health
        run: |
          echo "Waiting for backend /health..."
          for i in {1..40}; do
            if curl -sS http://localhost:8000/health | grep -q '"status":"ok"'; then
              echo "backend healthy"; break
            fi
            sleep 3
          done
          curl -sS http://localhost:8000/health

      - name: Run measurements process smoke test
        run: |
          set -euo pipefail
          # make a unique test email per run
          TEST_EMAIL="ci_smoke+${GITHUB_RUN_ID}@example.com"
          export TEST_EMAIL
          echo "Using TEST_EMAIL=$TEST_EMAIL"

          # create tiny PNG (1x1 transparent) to POST
          IMG_B64='iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR4nGNgYAAAAAMAASsJTYQAAAAASUVORK5CYII='
          echo "$IMG_B64" | base64 -d > front.png
          for f in back left right; do
            cp front.png "${f}.png"
          done

          # register (ignore error if already exists)
          curl -sS -X POST http://localhost:8000/api/v1/auth/register \
            -H 'Content-Type: application/json' \
            -d "{\"email\":\"${TEST_EMAIL}\",\"password\":\"password123\",\"first_name\":\"CI\",\"last_name\":\"Smoke\",\"role\":\"customer\"}" || true

          # login and obtain token (use url-encoding to preserve + in email)
          TOKEN=$(curl -sS -X POST http://localhost:8000/api/v1/auth/login --data-urlencode "username=${TEST_EMAIL}" --data-urlencode "password=password123" | jq -r .access_token)
          if [ -z "$TOKEN" ] || [ "$TOKEN" = "null" ]; then
            echo "Failed to login or obtain token"; exit 1
          fi

          # POST to /api/v1/measurements/process
          RESP=$(curl -s -w "\n%{http_code}" -X POST http://localhost:8000/api/v1/measurements/process \
            -H "Authorization: Bearer $TOKEN" \
            -F "photo_front=@front.png" -F "photo_back=@back.png" -F "photo_left=@left.png" -F "photo_right=@right.png" \
            -F "height=170" -F "weight=70")

          HTTP_STATUS=$(tail -n1 <<< "$RESP")
          BODY=$(sed '$d' <<< "$RESP")
          echo "HTTP status: $HTTP_STATUS"
          echo "$BODY" | jq -C . || true
          if [ "$HTTP_STATUS" != "200" ]; then
            echo "Process endpoint did not return 200"; exit 1
          fi
          # ensure expected keys exist
          echo "$BODY" | jq -e '.measurements and .confidence_score' >/dev/null

          # Extract measurement id for further integration checks
          MEASUREMENT_ID=$(echo "$BODY" | jq -r .id)
          echo "Created measurement id: $MEASUREMENT_ID"

          # Update measurement (change chest measurement)
          UPDATE_PAYLOAD='{"measurements": {"chest": 111.0, "waist": 80.0, "hip": 98.0}}'
          UPD_RESP=$(curl -s -w "\n%{http_code}" -X PUT http://localhost:8000/api/v1/measurements/${MEASUREMENT_ID} \
            -H "Authorization: Bearer $TOKEN" -H 'Content-Type: application/json' \
            -d "$UPDATE_PAYLOAD")
          UPD_STATUS=$(tail -n1 <<< "$UPD_RESP")
          UPD_BODY=$(sed '$d' <<< "$UPD_RESP")
          echo "Update HTTP status: $UPD_STATUS"
          echo "$UPD_BODY" | jq -C . || true
          if [ "$UPD_STATUS" != "200" ]; then
            echo "Failed to update measurement"; exit 1
          fi
          echo "$UPD_BODY" | jq -e '.measurements.chest == 111.0' >/dev/null

          # Skip deletion in CI so we can verify DB persistence afterwards
          echo "Skipping measurement delete in CI to allow DB persistence checks"

          # Negative AI response: force AI service to return unsuccessful status
          NEG_RESP=$(curl -s -w "\n%{http_code}" -X POST http://localhost:8000/api/v1/measurements/process \
            -H "Authorization: Bearer $TOKEN" \
            -F "photo_front=@front.png" -F "photo_back=@back.png" -F "photo_left=@left.png" -F "photo_right=@right.png" \
            -F "height=170" -F "weight=70" -F "force_error=error")
          NEG_STATUS=$(tail -n1 <<< "$NEG_RESP")
          NEG_BODY=$(sed '$d' <<< "$NEG_RESP")
          echo "Negative AI HTTP status: $NEG_STATUS"
          echo "$NEG_BODY" | jq -C . || true
          # Expect backend to respond with 500 when AI returns unsuccessful status
          if [ "$NEG_STATUS" != "500" ]; then
            echo "Negative AI scenario did not return expected 500"; exit 1
          fi

      - name: Verify DB persistence (query from backend)
        run: |
          set -euo pipefail
          echo "Verifying measurement was persisted in DB (using backend container)"
          docker compose exec -T backend bash -lc "export TEST_EMAIL='${TEST_EMAIL}'; python /workspaces/Qeyafa/backend/ci/check_db.py"

      - name: Prepare logs archive (create ci-logs.tar.gz)
        if: always()
        run: |
          set -euo pipefail
          mkdir -p ci-logs || true
          echo "ci-logs contents on runner before collecting:"
          ls -lah ci-logs || true
          if [ -f ci-logs/alembic.log ]; then echo "alembic.log present"; else echo "alembic.log missing"; fi
          # collect compose logs (no-color), ps and top for debugging
          docker compose --env-file .ci.env -f docker-compose.ci.yml logs --no-color > ci-logs/compose.log 2>&1 || true
          docker compose --env-file .ci.env -f docker-compose.ci.yml ps -a > ci-logs/ps.txt 2>&1 || true
          docker compose --env-file .ci.env -f docker-compose.ci.yml top > ci-logs/top.txt 2>&1 || true
          # collect service-specific logs if present; ignore errors
          docker compose --env-file .ci.env -f docker-compose.ci.yml logs backend --no-color > ci-logs/backend.log 2>&1 || true
          docker compose --env-file .ci.env -f docker-compose.ci.yml logs tester --no-color > ci-logs/tester.log 2>&1 || true
          tar -czf ci-logs.tar.gz ci-logs || true
          echo "created archive:" && ls -lah ci-logs.tar.gz || true

      - name: Upload logs artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-ci-logs
          path: ci-logs.tar.gz

      - name: Tear down compose services
        if: always()
        run: |
          set -euo pipefail
          if [ -f .ci.env ]; then
            docker compose --env-file .ci.env -f docker-compose.ci.yml down -v || true
            rm -f .ci.env || true
          else
            docker compose down -v || true
          fi
